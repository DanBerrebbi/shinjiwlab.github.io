---
layout: page
title: Open-source
permalink: /open_source

nav: true
order: 4
---

Our lab has been led and participated in the development of several open-source toolkits and datasets. Followings are some selected ones.

## Softwares

<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25">
      <a href="https://github.com/espnet/espnet">
      	<img src="{{ site.baseurl }}/assets/img/espnet_logo1.png" width="150" />
      </a>
</td>
<td>
  <strong>ESPnet</strong> is an end-to-end speech processing toolkit, with a broad coverage of speech recognition, text-to-speech, speech enhancement/separation, and speech translation. ESPnet uses pytorch as a main deep learning engine, and also follows Kaldi style data processing, feature extraction/format, and recipes to provide a complete setup for speech recognition and other speech processing experiments.
</td></tr>
</table>
<hr />

<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25" style="display:table-cell; vertical-align:middle; text-align:center">
      <a href="https://github.com/kaldi-asr/kaldi">
      	<img src="{{ site.baseurl }}/assets/img/kaldi-logo.png" width="100" />
      </a>
</td>
<td>
  <strong>Kaldi</strong> is a toolkit for speech recognition written in C++ and licensed under the Apache License v2.0. Kaldi is intended for use by speech recognition researchers.
</td></tr>
</table>
<hr />

<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25">
      <a href="https://github.com/s3prl/s3prl">
      	<img src="{{ site.baseurl }}/assets/img/S3PRL-logo.png" width="150" />
      </a>
</td>
<td>
  This is an open source toolkit called <strong>s3prl</strong>, which stands for <strong>S</strong>elf-<strong>S</strong>upervised <strong>S</strong>peech <strong>P</strong>re-training and <strong>R</strong>epresentation <strong>L</strong>earning. Self-supervised speech pre-trained models are called <strong>upstream</strong> in this toolkit, and are utilized in various <strong>downstream</strong> tasks.
</td></tr>
</table>
<hr />

## Datasets

<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25">
      <a href="https://chimechallenge.github.io/chime6/">
      	<img src="{{ site.baseurl }}/assets/img/chime-logo.png" width="150" />
      </a>
</td>
<td>
  Following the success of the 1st, 2nd, 3rd, 4th and 5th CHiME challenges, we are pleased to announce the 6th <strong>CHiME</strong> Speech Separation and Recognition Challenge (CHiME-6). The new challenge will consider the problem of distant multi-microphone conversational speech diarization and recognition in everyday home environments. Speech material was elicited using a dinner party scenario with efforts taken to capture data that is representative of natural conversational speech.
</td></tr>
</table>
<hr />

<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25">
      <a href="http://www.openslr.org/89/">
      	ASR corpus for endangered language documentation (Yoloxóchitl Mixtec)
      </a>
</td>
<td>
  Substantive material of <strong>Yoloxóchitl Mixtec</strong> speech corpus (Glottocode: yolo1241 | ISO 639-3 = xty) presented here was brought together over a period of just over 10 years by Jonathan D. Amith (PI) and Rey Castillo García a native speaker linguist from the community of Yoloxóchitl. The corpus is designed for ASR research in endagnered language documentation.
</td></tr>
</table>
<hr />


<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25">
      <a href="http://www.openslr.org/89/">
      	ASR and ST corpus for endangered language documentation (Puebla Nahuatl)
      </a>
</td>
<td>
  The substantive material of <strong>Puebla Nahuatl</strong> speech corpus was gathered over ten years by Jonathan D. Amith (PI) and a team of native speaker colleagues who have participated in the project for many years, one from its inception in 2009. The corpus is designed for ASR & MT research in endagnered language documentation.
</td></tr>
</table>
<hr />