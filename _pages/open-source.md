---
layout: page
title: Open-source
permalink: /open_source

nav: true
order: 4
---

Our lab has been led and participated in the development of several open-source toolkits and datasets. The followings are some selected ones.

### Softwares

<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25">
      <a href="https://github.com/espnet/espnet">
        <img src="{{ site.baseurl }}/assets/img/espnet_logo1.png" width="150" />
      </a>
</td>
<td>
  <strong>ESPnet</strong> is an end-to-end speech processing toolkit, with a broad coverage of speech recognition, text-to-speech, speech enhancement/separation, and speech translation. ESPnet uses pytorch as a main deep learning engine, and also follows Kaldi style data processing, feature extraction/format, and recipes to provide a complete setup for speech recognition and other speech processing experiments.
</td></tr>
</table>
<hr />

<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25" style="display:table-cell; vertical-align:middle; text-align:center">
      <a href="https://github.com/kaldi-asr/kaldi">
        <img src="{{ site.baseurl }}/assets/img/kaldi-logo.png" width="100" />
      </a>
</td>
<td>
  <strong>Kaldi</strong> is a toolkit for speech recognition written in C++ and licensed under the Apache License v2.0. Kaldi is intended for use by speech recognition researchers.
</td></tr>
</table>
<hr />

<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25">
      <a href="https://github.com/s3prl/s3prl">
        <img src="{{ site.baseurl }}/assets/img/S3PRL-logo.png" width="150" />
      </a>
</td>
<td>
  This is an open source toolkit called <strong>s3prl</strong>, which stands for <strong>S</strong>elf-<strong>S</strong>upervised <strong>S</strong>peech <strong>P</strong>re-training and <strong>R</strong>epresentation <strong>L</strong>earning. Self-supervised speech pre-trained models are called <strong>upstream</strong> in this toolkit, and are utilized in various <strong>downstream</strong> tasks.
</td></tr>
</table>
<hr />

<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25" style="display:table-cell; vertical-align:middle; text-align:center">
      <a href="https://github.com/freewym/espresso">
        <img src="{{ site.baseurl }}/assets/img/espresso_logo.png" width="100" />
      </a>
</td>
<td>
  <strong>Espresso</strong> is an open-source, modular, extensible end-to-end neural automatic speech recognition (ASR) toolkit based on the deep learning library PyTorch and the popular neural machine translation toolkit fairseq. Espresso supports distributed training across GPUs and computing nodes, and features various decoding approaches commonly employed in ASR, including look-ahead word-based language model fusion, for which a fast, parallelized decoder is implemented.
</td></tr>
</table>
<hr />

### Datasets

<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25">
      <a href="https://chimechallenge.github.io/chime6/">
        <img src="{{ site.baseurl }}/assets/img/chime-logo.png" width="150" />
      </a>
</td>
<td>
  Following the success of the 1st, 2nd, 3rd, 4th and 5th CHiME challenges, we are pleased to announce the 6th <strong>CHiME</strong> Speech Separation and Recognition Challenge (CHiME-6). The new challenge will consider distant multi-microphone conversational speech diarization and recognition in everyday home environments. Speech material was elicited using a dinner party scenario with efforts taken to capture data that is representative of natural conversational speech.
</td></tr>
</table>
<hr />

<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25">
      <a href="https://datasets.kensho.com/datasets/spgispeech">
        SPGISpeech
      </a>
</td>
<td>
  <strong>SPGISpeech</strong> is a corpus of 5,000 hours of professionally-transcribed financial audio. In contrast to previous transcription datasets, SPGISpeech contains a broad cross-section of L1 and L2 English accents, strongly varying audio quality, and both spontaneous and narrated speech. The transcripts have each been cross-checked by multiple professional editors for high accuracy and are fully formatted, including capitalization, punctuation, and denormalization of non-standard words.
</td></tr>
</table>
<hr />

<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25">
      <a href="http://www.openslr.org/89/">
        ASR corpus for endangered language documentation (Yoloxóchitl Mixtec)
      </a>
</td>
<td>
  Substantive material of <strong>Yoloxóchitl Mixtec</strong> speech corpus (Glottocode: yolo1241 | ISO 639-3 = xty) presented here was brought together over ten years by Jonathan D. Amith (PI) and Rey Castillo García, a native speaker linguist from the community of Yoloxóchitl. The corpus is designed for ASR research in endangered language documentation.
</td></tr>
</table>
<hr />


<table cellspacing="0" cellpadding="0">
<tr>
<td class="col-sm w-25">
      <a href="http://www.openslr.org/89/">
        ASR and ST corpus for endangered language documentation (Puebla Nahuatl)
      </a>
</td>
<td>
  The substantive material of <strong>Puebla Nahuatl</strong> speech corpus was gathered over ten years by Jonathan D. Amith (PI) and a team of native-speaker colleagues who have participated in the project for many years, one from its inception in 2009. The corpus is designed for ASR & MT research in endangered language documentation.
</td></tr>
</table>
<hr />